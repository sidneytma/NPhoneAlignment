{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc00945a",
   "metadata": {},
   "source": [
    "# N-phone Forced Alignment\n",
    "Extension of Jian Zhu's [Charsiu forced alignment](https://github.com/lingjzhu/charsiu) for diphones, triphones, and all n-phones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043beb4c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d42c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidneyma/anaconda3/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "#from Charsiu import charsiu_forced_aligner\n",
    "#charsiu = charsiu_forced_aligner(aligner=\"charsiu/en_w2v2_fc_10ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8f859",
   "metadata": {},
   "source": [
    "### Charsiu installation\n",
    "\n",
    "Based on Zhu's setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463660ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install datasets transformers\n",
    "!pip install g2p_en praatio librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists, join, expanduser\n",
    "\n",
    "os.chdir(expanduser(\"~\"))\n",
    "charsiu_dir = 'charsiu'\n",
    "if exists(charsiu_dir):\n",
    "    !rm -rf /root/charsiu\n",
    "if not exists(charsiu_dir):\n",
    "    ! git clone -b development https://github.com/lingjzhu/$charsiu_dir\n",
    "        ! cd charsiu && git checkout && cd -\n",
    "\n",
    "os.chdir(charsiu_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88293ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append('src/')\n",
    "sys.path.insert(0,'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15486f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Charsiu import charsiu_forced_aligner\n",
    "charsiu = charsiu_forced_aligner(aligner='charsiu/en_w2v2_fc_10ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73520900",
   "metadata": {},
   "source": [
    "## Phoneme alignment\n",
    "Collecting the original, monophone alignment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877e87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_16kHz(audio_filename):\n",
    "    audio = AudioSegment.from_file(audio_filename)\n",
    "    resampled_audio = audio.set_frame_rate(16000)\n",
    "    \n",
    "    audio_16kHz_filename = f\"audio_16kHz/{audio_filename}_16kHz.wav\"\n",
    "    resampled_audio.export(audio_16kHz_filename, format=\"wav\")\n",
    "    \n",
    "    return audio_16kHz_filename\n",
    "\n",
    "def run_alignment(audio_filename, input_sentence):\n",
    "    # file must be 16kHz\n",
    "    return charsiu.align(input_sentence, audio_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0c072",
   "metadata": {},
   "source": [
    "## N-phoneme alignment\n",
    "Extending this by finding the timepoints for n-phones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97ad86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nphone_alignment_data(alignment_data, n): \n",
    "    # if n=1, just return the alignment data\n",
    "    if n == 1:\n",
    "        return alignment_data\n",
    "    \n",
    "    def get_nphones(phones, n):\n",
    "        num_nphones = len(phones) - (n-1)\n",
    "        return [phones[i:i+n] for i in range(num_nphones)]\n",
    "\n",
    "    def get_nphone_label(nphone):\n",
    "        nphone_label = \"\"\n",
    "        for phone in nphone:\n",
    "            nphone_label += phone[2] + \" \"\n",
    "        return nphone_label[:-1]\n",
    "        \n",
    "    nphone_alignment = []\n",
    "    alignment_chunks = get_nphones(alignment_data, n)\n",
    "    \n",
    "    for nphone in alignment_chunks:\n",
    "        \n",
    "        start_time = nphone[0][0]\n",
    "        end_time = nphone[-1][1]\n",
    "        nphone_label = get_nphone_label(nphone)\n",
    "        \n",
    "        nphone_alignment.append((start_time, end_time, nphone_label))\n",
    "    return nphone_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e63dc9",
   "metadata": {},
   "source": [
    "## Testing/review functions\n",
    "Two easy ways for a human to verify the results:\n",
    "1) reading the output\n",
    "2) reviewing the chopped audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2bcd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_alignment_data(alignment_data, audio_filename, input_sentence, n):\n",
    "    nphone_list = [nphone[2] for nphone in alignment_data]\n",
    "    print(f\"\"\"Reviewing alignment data...\n",
    "Audio file: {audio_filename}\n",
    "Input sentence: {input_sentence}\n",
    "N-phone type: {n}-phones\n",
    "\n",
    "N-phones found: {nphone_list}\n",
    "\"\"\")\n",
    "\n",
    "def review_alignment_data_audio(alignment_data, audio_filename):\n",
    "    \n",
    "    def get_audio_segment(audio_filename, start_time, end_time):\n",
    "        audio = AudioSegment.from_file(audio_filename)\n",
    "        return audio[start_time*1000:end_time*1000]\n",
    "    \n",
    "    for start_time, end_time, nphone in alignment_data:\n",
    "        print(f\"Playing {nphone}...\")\n",
    "        audio = get_audio_segment(audio_filename, start_time, end_time)\n",
    "        for _ in range(3):\n",
    "            play(audio)\n",
    "            time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15dc78",
   "metadata": {},
   "source": [
    "## Data I/O functions\n",
    "Reading/writing alignment data from/to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2031f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cache(cache_name=\"nphone_data_cache.json\"): # read in the JSON file\n",
    "    if not os.path.exists(cache_name):\n",
    "        return {}\n",
    "    return # the json file as a readable object\n",
    "\n",
    "def upload_alignment_data(alignment_data, audio_filename, cache_name=\"nphone_data_cache.json\"): # upload it to the JSON file\n",
    "    if not os.path.exists(cache_name):\n",
    "        # make the json file. it should be empty.\n",
    "        cache = read_cache(cache_name)\n",
    "    for start_time, end_time, nphone in alignment_data:\n",
    "        audio_obj = {\n",
    "            \"audio_filename\": audio_filename, \n",
    "            \"start_time\": start_time, \n",
    "            \"end_time\": end_time,\n",
    "                    }\n",
    "        if nphone in cache:\n",
    "            cache[\"nphone\"].append(audio_obj)\n",
    "        else:\n",
    "            cache[\"nphone\"] = [audio_obj]\n",
    "    # upload this cache to the json file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163a5e5",
   "metadata": {},
   "source": [
    "## Example usage\n",
    "Collecting diphone alignments on an example audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3e28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "AUDIO_FILENAME = \"audio/test_audio.wav\"\n",
    "INPUT_SENTENCE = \"\"\"I went to watch a movie instead, and I met my friend there.\"\"\"\n",
    "N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f250567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare 16kHz audio and run alignment\n",
    "audio_16kHz_filename = get_audio_16kHz(AUDIO_FILENAME)\n",
    "alignment_data = run_alignment(audio_16kHz_filename, INPUT_SENTENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2f60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_data = [[0.0, 0.33, \"[SIL]\"], [0.33, 0.46, \"AY\"], [0.46, 0.56, \"W\"], [0.56, 0.6, \"EH\"], [0.6, 0.63, \"N\"], [0.63, 0.72, \"T\"], [0.72, 0.75, \"UW\"], [0.75, 0.85, \"W\"], [0.85, 0.94, \"AA\"], [0.94, 1.02, \"CH\"], [1.02, 1.08, \"AH\"], [1.08, 1.15, \"M\"], [1.15, 1.23, \"UW\"], [1.23, 1.3, \"V\"], [1.3, 1.36, \"IY\"], [1.36, 1.41, \"IH\"], [1.41, 1.47, \"N\"], [1.47, 1.54, \"S\"], [1.54, 1.61, \"T\"], [1.61, 1.73, \"EH\"], [1.73, 1.83, \"D\"], [1.83, 1.96, \"[SIL]\"], [1.96, 2.01, \"AH\"], [2.01, 2.04, \"N\"], [2.04, 2.07, \"D\"], [2.07, 2.12, \"AY\"], [2.12, 2.21, \"M\"], [2.21, 2.28, \"EH\"], [2.28, 2.31, \"T\"], [2.31, 2.36, \"M\"], [2.36, 2.43, \"AY\"], [2.43, 2.55, \"F\"], [2.55, 2.59, \"R\"], [2.59, 2.64, \"EH\"], [2.64, 2.7, \"N\"], [2.7, 2.73, \"D\"], [2.73, 2.76, \"DH\"], [2.76, 2.8, \"EH\"], [2.8, 2.96, \"R\"], [2.96, 3.12, \"[SIL]\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dfe98a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.46, '[SIL] AY'),\n",
       " (0.33, 0.56, 'AY W'),\n",
       " (0.46, 0.6, 'W EH'),\n",
       " (0.56, 0.63, 'EH N'),\n",
       " (0.6, 0.72, 'N T'),\n",
       " (0.63, 0.75, 'T UW'),\n",
       " (0.72, 0.85, 'UW W'),\n",
       " (0.75, 0.94, 'W AA'),\n",
       " (0.85, 1.02, 'AA CH'),\n",
       " (0.94, 1.08, 'CH AH'),\n",
       " (1.02, 1.15, 'AH M'),\n",
       " (1.08, 1.23, 'M UW'),\n",
       " (1.15, 1.3, 'UW V'),\n",
       " (1.23, 1.36, 'V IY'),\n",
       " (1.3, 1.41, 'IY IH'),\n",
       " (1.36, 1.47, 'IH N'),\n",
       " (1.41, 1.54, 'N S'),\n",
       " (1.47, 1.61, 'S T'),\n",
       " (1.54, 1.73, 'T EH'),\n",
       " (1.61, 1.83, 'EH D'),\n",
       " (1.73, 1.96, 'D [SIL]'),\n",
       " (1.83, 2.01, '[SIL] AH'),\n",
       " (1.96, 2.04, 'AH N'),\n",
       " (2.01, 2.07, 'N D'),\n",
       " (2.04, 2.12, 'D AY'),\n",
       " (2.07, 2.21, 'AY M'),\n",
       " (2.12, 2.28, 'M EH'),\n",
       " (2.21, 2.31, 'EH T'),\n",
       " (2.28, 2.36, 'T M'),\n",
       " (2.31, 2.43, 'M AY'),\n",
       " (2.36, 2.55, 'AY F'),\n",
       " (2.43, 2.59, 'F R'),\n",
       " (2.55, 2.64, 'R EH'),\n",
       " (2.59, 2.7, 'EH N'),\n",
       " (2.64, 2.73, 'N D'),\n",
       " (2.7, 2.76, 'D DH'),\n",
       " (2.73, 2.8, 'DH EH'),\n",
       " (2.76, 2.96, 'EH R'),\n",
       " (2.8, 3.12, 'R [SIL]')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect nphone alignment data\n",
    "nphone_alignment_data = get_nphone_alignment_data(alignment_data, N)\n",
    "nphone_alignment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3828488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing alignment data...\n",
      "Audio file: audio/test_audio.wav\n",
      "Input sentence: I went to watch a movie instead, and I met my friend there.\n",
      "N-phone type: 2-phones\n",
      "\n",
      "N-phones found: ['[SIL] AY', 'AY W', 'W EH', 'EH N', 'N T', 'T UW', 'UW W', 'W AA', 'AA CH', 'CH AH', 'AH M', 'M UW', 'UW V', 'V IY', 'IY IH', 'IH N', 'N S', 'S T', 'T EH', 'EH D', 'D [SIL]', '[SIL] AH', 'AH N', 'N D', 'D AY', 'AY M', 'M EH', 'EH T', 'T M', 'M AY', 'AY F', 'F R', 'R EH', 'EH N', 'N D', 'D DH', 'DH EH', 'EH R', 'R [SIL]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visual review\n",
    "review_alignment_data(nphone_alignment_data, AUDIO_FILENAME, INPUT_SENTENCE, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ec59add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing [SIL] AY...\n",
      "Playing AY W...\n",
      "Playing W EH...\n",
      "Playing EH N...\n",
      "Playing N T...\n",
      "Playing T UW...\n",
      "Playing UW W...\n",
      "Playing W AA...\n",
      "Playing AA CH...\n",
      "Playing CH AH...\n",
      "Playing AH M...\n",
      "Playing M UW...\n",
      "Playing UW V...\n",
      "Playing V IY...\n",
      "Playing IY IH...\n",
      "Playing IH N...\n",
      "Playing N S...\n",
      "Playing S T...\n",
      "Playing T EH...\n",
      "Playing EH D...\n",
      "Playing D [SIL]...\n",
      "Playing [SIL] AH...\n",
      "Playing AH N...\n",
      "Playing N D...\n",
      "Playing D AY...\n",
      "Playing AY M...\n",
      "Playing M EH...\n",
      "Playing EH T...\n",
      "Playing T M...\n",
      "Playing M AY...\n",
      "Playing AY F...\n",
      "Playing F R...\n",
      "Playing R EH...\n",
      "Playing EH N...\n",
      "Playing N D...\n",
      "Playing D DH...\n",
      "Playing DH EH...\n",
      "Playing EH R...\n",
      "Playing R [SIL]...\n"
     ]
    }
   ],
   "source": [
    "# Auditory review\n",
    "review_alignment_data_audio(nphone_alignment_data, AUDIO_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa270cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
